{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1894ccac",
   "metadata": {},
   "source": [
    "# Data Manipulation Studio\n",
    "\n",
    "For this studio, we will revisit the data set from our last studio. If you recall, California farmers were looking for advice on growing pumpkins. We will use the same [pumpkins dataset](https://www.kaggle.com/usda/a-year-of-pumpkin-prices) as provided by the U.S. Department of Agriculture. You may have to clean data in the process of data manipulation, so feel free to pull up your notebook from the last class's studio.\n",
    "\n",
    "We will now be focusing our attention on a different region in the United States, the Northeast. When you open up the `dataset` folder, you will have 13 CSVs, including the San Francisco and Los Angeles data from the last lesson. The 13 CSVs are each a different terminal market in the United States.\n",
    "\n",
    "A **terminal market** is a central site, often in a metropolitan area, that serves as an assembly and trading place for commodities. Terminal markets for agricultural commodities are usually at or near major transportation hubs. [Definition Source](https://en.wikipedia.org/wiki/Terminal_market#:~:text=A%20terminal%20market%20is%20a,or%20near%20major%20transportation%20hubs)\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Import the CSVs for each of the following cities: Baltimore, Boston, New York, and Philadelphia. Set up a dataframe for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c9a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and CSVs. Make some dataframes!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_baltimore = pd.read_csv(r\"C:\\Users\\lred1\\Desktop\\Launchcode\\SQL\\clone\\data-analysis-projects\\data-manipulation\\studio\\data-manipulation-studio\\dataset\\baltimore_9-24-2016_9-30-2017.csv\")\n",
    "data_boston = pd.read_csv(r\"C:\\Users\\lred1\\Desktop\\Launchcode\\SQL\\clone\\data-analysis-projects\\data-manipulation\\studio\\data-manipulation-studio\\dataset\\boston_9-24-2016_9-30-2017.csv\")\n",
    "data_newyork = pd.read_csv(r\"C:\\Users\\lred1\\Desktop\\Launchcode\\SQL\\clone\\data-analysis-projects\\data-manipulation\\studio\\data-manipulation-studio\\dataset\\new-york_9-24-2016_9-30-2017.csv\")\n",
    "data_philly = pd.read_csv(r\"C:\\Users\\lred1\\Desktop\\Launchcode\\SQL\\clone\\data-analysis-projects\\data-manipulation\\studio\\data-manipulation-studio\\dataset\\philadelphia_9-24-2016_9-30-2017.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda42f",
   "metadata": {},
   "source": [
    "## Clean Your Data\n",
    "\n",
    "In the last lesson, we cleaned the data related to San Francisco. Pull up your notebook from the last lesson and use it as a reference to clean up these new dataframes.\n",
    "\n",
    "**Recommended cleaning steps:**\n",
    "1. Handle missing values in the `Type` column (fill with \"Conventional\" if needed)\n",
    "2. Drop irrelevant columns such as `Grade` (only applies to canned pumpkins)\n",
    "3. Drop columns with high percentages of missing data that aren't needed for analysis\n",
    "4. Check for and address any other data quality issues you notice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98abc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean your data here!\n",
    "data_baltimore[\"Type\"] = data_baltimore[\"Type\"].fillna(\"Conventional\")\n",
    "data_boston[\"Type\"] = data_boston[\"Type\"].fillna(\"Conventional\")\n",
    "data_newyork[\"Type\"] = data_newyork[\"Type\"].fillna(\"Conventional\")\n",
    "data_philly[\"Type\"] = data_philly[\"Type\"].fillna(\"Conventional\")\n",
    "data_baltimore = data_baltimore.drop([\"Grade\"], axis=1) \n",
    "data_boston = data_boston.drop([\"Grade\"], axis=1) \n",
    "data_newyork = data_newyork.drop([\"Grade\"], axis=1) \n",
    "data_philly = data_philly.drop([\"Grade\"], axis=1) \n",
    "data_baltimore = data_baltimore.drop([\"Environment\",\"Quality\",\"Condition\",\"Appearance\",\"Storage\",\"Crop\",\"Trans Mode\"], axis=1) \n",
    "data_boston = data_boston.drop([\"Environment\",\"Quality\",\"Condition\",\"Appearance\",\"Storage\",\"Crop\",\"Trans Mode\"], axis=1) \n",
    "data_newyork = data_newyork.drop([\"Environment\",\"Quality\",\"Condition\",\"Appearance\",\"Storage\",\"Crop\",\"Trans Mode\"], axis=1) \n",
    "data_philly = data_philly.drop([\"Environment\",\"Quality\",\"Condition\",\"Appearance\",\"Storage\",\"Crop\",\"Trans Mode\"], axis=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b01b9",
   "metadata": {},
   "source": [
    "## Combine Your Data\n",
    "\n",
    "Now that you have four clean sets of data, combine all four into one dataframe that represents the entire Northeast region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da059f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Commodity Name     674\n",
       "City Name          674\n",
       "Type               674\n",
       "Package            674\n",
       "Variety            672\n",
       "Sub Variety         83\n",
       "Date               674\n",
       "Low Price          674\n",
       "High Price         674\n",
       "Mostly Low         674\n",
       "Mostly High        674\n",
       "Origin             669\n",
       "Origin District     81\n",
       "Item Size          625\n",
       "Color              356\n",
       "Environment          0\n",
       "Unit of Sale       106\n",
       "Quality              0\n",
       "Condition            0\n",
       "Appearance           0\n",
       "Storage              0\n",
       "Crop                 0\n",
       "Repack             674\n",
       "Trans Mode           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the four dataframes into one!\n",
    "data_all = pd.concat(\n",
    "    [data_baltimore, data_boston, data_newyork, data_philly],\n",
    "    axis=0,           \n",
    "    ignore_index=True \n",
    ")\n",
    "data_all.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590082f",
   "metadata": {},
   "source": [
    "## Answer Some Questions\n",
    "\n",
    "Use `groupby()` and `agg()` to answer the following two questions:\n",
    "\n",
    "1. What is the mean low and high prices for each type of **unit of sale** in the Northeast region?\n",
    "2. For the Northeast region, what is the total count of transactions (rows) for each pumpkin variety that came into terminal markets for the year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c839639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Low Price  High Price\n",
      "Variety                                         \n",
      "BIG MACK TYPE             129.454545  147.272727\n",
      "BLUE TYPE                 260.000000  285.000000\n",
      "CINDERELLA                206.051282  220.974359\n",
      "FAIRYTALE                 198.783784  214.108108\n",
      "HOWDEN TYPE               152.834821  177.098214\n",
      "HOWDEN WHITE TYPE         170.000000  180.000000\n",
      "KNUCKLE HEAD              238.888889  260.555556\n",
      "MINIATURE                  16.391753   17.886598\n",
      "MIXED HEIRLOOM VARIETIES  210.000000  230.000000\n",
      "PIE TYPE                  133.404040  148.118687\n"
     ]
    }
   ],
   "source": [
    "# Put your code here to find the mean low and high prices in the Northeast region for each type of unit of sale.\n",
    "mean_prices = data_all.groupby(\"Variety\")[[\"Low Price\", \"High Price\"]].mean()\n",
    "print(mean_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b23352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variety\n",
       "HOWDEN TYPE                 224\n",
       "PIE TYPE                    198\n",
       "MINIATURE                    97\n",
       "BIG MACK TYPE                55\n",
       "CINDERELLA                   39\n",
       "FAIRYTALE                    37\n",
       "KNUCKLE HEAD                  9\n",
       "BLUE TYPE                     7\n",
       "MIXED HEIRLOOM VARIETIES      4\n",
       "HOWDEN WHITE TYPE             2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code here to find the total count of transactions for each variety in the Northeast region.\n",
    "data_all[\"Variety\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5cff4",
   "metadata": {},
   "source": [
    "## Bonus Mission\n",
    "\n",
    "Try answering the same questions for a different region! Choose either:\n",
    "- **Midwest**: Chicago, Detroit, and St. Louis\n",
    "- **Southeast**: Atlanta, Columbia, and Miami\n",
    "\n",
    "Load, clean, and combine the data for your chosen region, then calculate:\n",
    "1. The mean low and high prices for each type of unit of sale\n",
    "2. The total count of transactions for each pumpkin variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d22b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the bonus mission if you have time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbc152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
